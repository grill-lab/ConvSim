{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/ubuntu/ConvSim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_classes import ConversationalTurn\n",
    "import shelve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"cast_cq_with_feedback\"\n",
    "with shelve.open(f\"../data/generated_conversations/{run_name}/turns_db\") as db:\n",
    "    for turn_id in db:\n",
    "        conversational_turn = db[turn_id]\n",
    "        if conversational_turn.user_utterance_type == \"feedback\":\n",
    "            # build conversation list\n",
    "            conversation = []\n",
    "            for historical_turn in conversational_turn.conversation_history:\n",
    "                conversation.append(historical_turn['utterance'])\n",
    "            conversation.append(conversational_turn.user_utterance)\n",
    "            rewritten_utterance = conversational_turn.rewritten_utterance.replace(\"USER: \", \"\").strip()\n",
    "            dataset.append({\n",
    "                \"conversation\": conversation,\n",
    "                \"rewrite\": rewritten_utterance,\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"cast_rewrites_no_feedback\"\n",
    "with shelve.open(f\"../data/generated_conversations/{run_name}/turns_db\") as db:\n",
    "    for turn_id in db:\n",
    "        conversational_turn = db[turn_id]\n",
    "        conversation = []\n",
    "        for historical_turn in conversational_turn.conversation_history:\n",
    "            conversation.append(historical_turn['utterance'])\n",
    "        conversation.append(conversational_turn.user_utterance)\n",
    "        rewritten_utterance = conversational_turn.rewritten_utterance.replace(\"USER: \", \"\").strip()\n",
    "        dataset.append({\n",
    "            \"conversation\": conversation,\n",
    "            \"rewrite\": rewritten_utterance,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = \"cast_response_with_feedback\"\n",
    "with shelve.open(f\"../data/generated_conversations/{run_name}/turns_db\") as db:\n",
    "    for turn_id in db:\n",
    "        conversational_turn = db[turn_id]\n",
    "        conversation = []\n",
    "        for historical_turn in conversational_turn.conversation_history:\n",
    "            conversation.append(historical_turn['utterance'])\n",
    "        conversation.append(conversational_turn.user_utterance)\n",
    "        rewritten_utterance = conversational_turn.rewritten_utterance.replace(\"USER: \", \"\").strip()\n",
    "        dataset.append({\n",
    "            \"conversation\": conversation,\n",
    "            \"rewrite\": rewritten_utterance,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conversation': ['I remember Glasgow hosting COP26 last year, but unfortunately I was out of the loop. What was it about?',\n",
       "  'The COP26 event is a global united Nations summit about climate change and how countries are planning to tackle it. The term “climate change” is often used as if it means the same thing as the term “global warming”. The National Academy of Sciences says “climate change” is growing in favor of “global warming” because it helps convey that there are other changes in addition to rising temperatures. In fact, “climate change” means major changes in temperature, rainfall, snow, or wind patterns lasting for decades or longer.',\n",
       "  'Interesting. What are the effects of these changes?',\n",
       "  'Are you looking for information on the effects of climate change on ecosystems, human health, or global economy?',\n",
       "  \"Yes, that's what I'm interested in.\"],\n",
       " 'rewrite': 'What are the impacts of climate change on the world?'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/ConvSim/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ubuntu/ConvSim/env/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:160: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "MODEL_NAME = \"castorini/t5-base-canard\" # \"t5-base\" #\"t5-base\" \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "dataset = Dataset.from_list(dataset)\n",
    "# dataset = dataset.select(range(10000))\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-25 17:23:21.817775: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-25 17:23:21.820173: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-25 17:23:21.872368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-25 17:23:22.734656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=MODEL_NAME)\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    parsed_conversations = [\" ||| \".join(conversation) for conversation in examples['conversation']]\n",
    "    print(parsed_conversations[0])\n",
    "    inputs = [prefix + conv for conv in parsed_conversations]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True)\n",
    "\n",
    "    labels = tokenizer(text_target=examples[\"rewrite\"], max_length=256, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/548 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’ve got an offer to make 20% monthly interest on my money. Do you think it’s legit? ||| Scams are targeted to insight human greed and desperation. However, there are red flags you can pick up from the way they pitch it. For example, guaranteed returns that are too good to be true in a short time period. Unless they’re predicting the future, it’s unlikely you can get these guaranteed returns of higher percentages (10%++) consistently. ||| What else should I be aware of? ||| Anosmia, a condition caused by the coronavirus, may be linked to a loss of sense of smell. Self-isolation for at least seven days can help reduce the spread of the infection. Additionally, hounding or job hopping can be a warning sign for a candidate who displays a pattern of resignation or has itchy feet. ||| Interesting. What else?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 548/548 [00:00<00:00, 2227.33 examples/s]\n",
      "Map: 100%|██████████| 61/61 [00:00<00:00, 1998.82 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What should I consider when buying a phone? ||| The design of the phone and the overall look and feel of the phone are very important. You should be comfortable with the way the phone looks and feels when you hold it in your hand. In addition, don’t be afraid to get a phone from a different manufacturer than you’re used to. Consider an older, used, or refurbished phone to save money. Sometimes a year-old or even a two-year-old device might give you everything you need. ||| I've heard iPhones look and feel great. Should I get one? ||| To select a cell phone, it is important to research several factors, including price, early termination fees, network availability, and other factors. Choosing a phone with a solid foundation will help you choose a plan that truly fits your needs. Price is also important to consider, as it can lead to a premium. Storage is also important, as it can slow down and cause problems, so it is important to research and compare prices. Additionally, showcasing a decent camera and having a good camera may be important, but it is also important to consider other factors such as price and availability. ||| What are the reasons to get an iPhone?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = MODEL_NAME.replace(\"/\", \"-\")\n",
    "TUNED_MODEL_NAME = f\"../../data/models/tuned-{MODEL_NAME}-rewriter-v2\"\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=TUNED_MODEL_NAME,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # eval_steps=5,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=20,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=128,\n",
    "    #generation_num_beams=4,\n",
    "    fp16=True,\n",
    "    # auto_find_batch_size=True,\n",
    "    # load_best_model_at_end=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='340' max='340' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [340/340 57:02, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.591093</td>\n",
       "      <td>0.303000</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.287800</td>\n",
       "      <td>26.803300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.269357</td>\n",
       "      <td>0.427400</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>0.392200</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>13.737700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.175722</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.279200</td>\n",
       "      <td>0.428200</td>\n",
       "      <td>0.432300</td>\n",
       "      <td>13.606600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.089726</td>\n",
       "      <td>0.462700</td>\n",
       "      <td>0.277900</td>\n",
       "      <td>0.429400</td>\n",
       "      <td>0.432000</td>\n",
       "      <td>15.065600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.061272</td>\n",
       "      <td>0.469300</td>\n",
       "      <td>0.290300</td>\n",
       "      <td>0.435900</td>\n",
       "      <td>0.439200</td>\n",
       "      <td>14.934400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.041786</td>\n",
       "      <td>0.489200</td>\n",
       "      <td>0.312100</td>\n",
       "      <td>0.452500</td>\n",
       "      <td>0.454500</td>\n",
       "      <td>15.688500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.009362</td>\n",
       "      <td>0.507500</td>\n",
       "      <td>0.330900</td>\n",
       "      <td>0.472900</td>\n",
       "      <td>0.475600</td>\n",
       "      <td>13.623000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.001888</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.324400</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.473800</td>\n",
       "      <td>13.393400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.998318</td>\n",
       "      <td>0.512200</td>\n",
       "      <td>0.338600</td>\n",
       "      <td>0.477000</td>\n",
       "      <td>0.480300</td>\n",
       "      <td>15.655700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.985497</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>0.333300</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>0.476000</td>\n",
       "      <td>15.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.980462</td>\n",
       "      <td>0.528600</td>\n",
       "      <td>0.347900</td>\n",
       "      <td>0.488400</td>\n",
       "      <td>0.491000</td>\n",
       "      <td>15.491800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.980985</td>\n",
       "      <td>0.533400</td>\n",
       "      <td>0.350300</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>0.496600</td>\n",
       "      <td>15.426200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.975652</td>\n",
       "      <td>0.532400</td>\n",
       "      <td>0.348300</td>\n",
       "      <td>0.485600</td>\n",
       "      <td>0.489300</td>\n",
       "      <td>15.590200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.974696</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>15.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.973992</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>15.409800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.973692</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.492700</td>\n",
       "      <td>0.494700</td>\n",
       "      <td>15.409800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=340, training_loss=1.0856819601619945, metrics={'train_runtime': 3428.4876, 'train_samples_per_second': 3.197, 'train_steps_per_second': 0.099, 'total_flos': 1.258562293069824e+16, 'train_loss': 1.0856819601619945, 'epoch': 19.71})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "rewriter = pipeline(\"text2text-generation\", model=trainer.model, tokenizer=trainer.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Can you provide me with a diet that is vegan-friendly, maintainable and not very hard to keep up with?'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewriter(\"Can you help me find a diet for myself? ||| What kind of diet do you want? ||| I want something that is vegan-friendly, maintainable and not very hard to keep up\", max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
